# -*- coding: utf-8 -*-
"""Diabetes_prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l0VqEUQXwbRnPpBYfEJjHgg4hXB9gCs1
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import math
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.feature_selection import RFE

from google.colab import files
uploaded = files.upload()

df = pd.read_csv("diabetes2.csv")

print(df.head())
print(df.isnull().sum())

plt.figure(figsize=(8,6))
sns.countplot(x='Outcome', data=df, palette='coolwarm')
plt.title('Distribution of Diabetes Outcome')
plt.show()

df.hist(figsize=(12, 10), bins=20, color='steelblue', edgecolor='black')
plt.suptitle('Feature Distributions', fontsize=16)
plt.show()

plt.figure(figsize=(10,8))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm")
plt.title("Feature Correlation Heatmap")
plt.show()

X = df.drop(columns=['Outcome'])
y = df['Outcome']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

rf = RandomForestClassifier(n_estimators=100, random_state=42)
rfe = RFE(rf, n_features_to_select=5)
X_selected = rfe.fit_transform(X_scaled, y)
selected_features = df.columns[:-1][rfe.support_]
print("Selected Features:", selected_features)

X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42, stratify=y)

param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 20],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy', n_jobs=-1)
grid_search.fit(X_train, y_train)
print("Best Parameters:", grid_search.best_params_)
best_model = grid_search.best_estimator_

y_pred = best_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')
print(classification_report(y_test, y_pred))

plt.figure(figsize=(6,4))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def compute_logistic_cost(X, y, w, b):
    m, n = X.shape
    cost = 0
    for i in range(m):
        z = np.dot(X[i], w) + b
        f_wb = sigmoid(z)
        cost += (-y[i] * np.log(f_wb) - (1 - y[i]) * np.log(1 - f_wb))
    return cost / m

def compute_gradient_logistic(X, y, w, b):
    m, n = X.shape
    dj_dw = np.zeros((n,))
    dj_db = 0
    for i in range(m):
        error = sigmoid(np.dot(X[i], w) + b) - y[i]
        for j in range(n):
            dj_dw[j] += error * X[i][j]
        dj_db += error
    return dj_dw / m, dj_db / m

def compute_gradient_descent_logistic(X, y, w_ini, b_ini, alpha, numiters):
    w = w_ini
    b = b_ini
    for i in range(numiters):
        dj_dw, dj_db = compute_gradient_logistic(X, y, w, b)
        w -= alpha * dj_dw
        b -= alpha * dj_db
    return w, b

np.random.seed(1)
initial_w = np.random.rand(X_selected.shape[1])
initial_b = 0.0
iterations = 1000
alpha = 0.1

w, b = compute_gradient_descent_logistic(X_selected, y, initial_w, initial_b, alpha, iterations)

def predict(X, w, b):
    return (sigmoid(np.dot(X, w) + b) >= 0.3).astype(int)

def precision(y_test, y_pred):
    tp = np.sum((y_test == 1) & (y_pred == 1))
    fp = np.sum((y_test == 0) & (y_pred == 1))
    return tp / (tp + fp) if tp + fp != 0 else 0

def recall(y_test, y_pred):
    tp = np.sum((y_test == 1) & (y_pred == 1))
    fn = np.sum((y_test == 1) & (y_pred == 0))
    return tp / (tp + fn) if tp + fn != 0 else 0

def f1_score(y_test, y_pred):
    prec = precision(y_test, y_pred)
    rec = recall(y_test, y_pred)
    return 2 * (prec * rec) / (prec + rec) if prec + rec != 0 else 0

def classification_report_custom(y_test, y_pred):
    return {
        'accuracy': accuracy(y_test, y_pred),
        'precision': precision(y_test, y_pred),
        'recall': recall(y_test, y_pred),
        'f1-score': f1_score(y_test, y_pred)
    }

def accuracy(y_test, y_pred):
    return np.mean(y_test == y_pred)

y_pred_lr = predict(X_selected, w, b)
print(f"Logistic Regression Accuracy: {accuracy(y, y_pred_lr) * 100:.2f}%")
print("Confusion Matrix:")
print(confusion_matrix(y, y_pred_lr))
print("Classification Report:")
print(classification_report_custom(y, y_pred_lr))

