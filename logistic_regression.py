# -*- coding: utf-8 -*-
"""Logistic_regression

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UzH9pUlDs8otcMvgAEV0zhmR7lHJV4fv
"""

import pandas as pd
import numpy as np
import math
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

from google.colab import files
uploaded = files.upload()

df = pd.read_csv("diabetes2.csv")

y=df['Outcome']

X=df.drop('Outcome',axis=1)

def zscore_normalize_features(X):
    miu   =np.mean(X,axis=0)
    sigma =np.std(X,axis=0)
    X_norm=(X-miu)/sigma
    return (X_norm,miu,sigma)

X_norm, X_mu, X_sigma = zscore_normalize_features(X)

def sigmoid(z):
    g = 1 / (1 + np.exp(-z))
    return g

def compute_logistic_cost(X,y,w,b):
    m,n=X.shape()
    Cost=0
    for i in range(m):
      z=np.dot(X[i],w)+b
      f_wb=sigmoid(z)
      Cost+=(-y[i]*np.log(f_wb)-(1-y[i])*np.log(1-f_wb))
    Cost=Cost/(m)
    return Cost

def compute_gradient_logistic(X,y,w,b):
    m,n=X.shape()
    dj_dw=np.zeros((n,))
    dj_db=0
    for i in range(m):
        error=(sigmoid(np.dot(X[i],w)+b))-y[i]
        for j in range(n):
            dj_dw[j]=dj_dw[j]+error*X[i][j]
        dj_db=dj_db+error
    dj_db=dj_db/m
    dj_dw=dj_dw/m
    return dj_dw,dj_db

def compute_logistic_cost_reg(X, y, w, b, lambda_):
    m, n = X.shape
    z = np.dot(X, w) + b
    f_wb = sigmoid(z)
    cost = -(np.dot(y, np.log(f_wb)) + np.dot((1 - y), np.log(1 - f_wb))) / m
    reg_cost = (lambda_ / (2 * m)) * np.sum(w**2)
    total_cost = cost + reg_cost
    return total_cost

def compute_logistic_gradient_reg(X, y, w, b, lambda_):
    m, n = X.shape
    z = np.dot(X, w) + b
    f_wb = sigmoid(z)
    error = f_wb - y
    dj_dw = (np.dot(X.T, error) / m) + (lambda_ / m) * w
    dj_db = np.sum(error) / m
    return dj_dw, dj_db

def compute_gradient_descent_logistic(X, y, w_ini, b_ini, alpha, numiters, lambda_):
    J_hist = []
    w = w_ini
    b = b_ini
    for i in range(numiters):
        dj_dw, dj_db = compute_logistic_gradient_reg(X, y, w, b, lambda_)
        w = w - alpha * dj_dw
        b = b - alpha * dj_db
        if i < 100000:
            J_hist.append(compute_logistic_cost_reg(X, y, w, b, lambda_))
        if i % math.ceil(numiters / 10) == 0:
            print(f"Iteration:{i:5d}, Cost:{J_hist[-1]:8.2f}")
    return w, b, J_hist

np.random.seed(1)
initial_w = 0.01 * (np.random.rand(8) - 0.5)
initial_b = 0.0
iterations = 1000
alpha = 0.1
lambda_ = 1


w, b, J_history = compute_gradient_descent_logistic(X_norm, y, initial_w, initial_b, alpha, iterations, lambda_)

def predict(X, w, b):
    z_wb = np.dot(X, w) + b
    f_wb = sigmoid(z_wb)
    p = (f_wb >= 0.30).astype(int)
    return p

def accuracy(X, y, w, b):
    p = predict(X, w, b)
    correct_predictions = np.sum(p == y)
    accuracy = correct_predictions / len(y)
    return accuracy

y_test=df['Outcome']
y_pred=np.round(predict(X_norm,w,b))

def accuracy(y_test, y_pred):
    correct_predictions = np.sum(y_test == y_pred)
    total_predictions = len(y_test)
    return correct_predictions / total_predictions

def precision(y_test, y_pred):

    tp = np.sum((y_test == 1) & (y_pred == 1))
    fp = np.sum((y_test == 0) & (y_pred == 1))
    return tp / (tp + fp) if tp + fp != 0 else 0

def recall(y_test, y_pred):

    tp = np.sum((y_test == 1) & (y_pred == 1))
    fn = np.sum((y_test == 1) & (y_pred == 0))
    return tp / (tp + fn) if tp + fn != 0 else 0

def f1_score(y_test, y_pred):
    prec = precision(y_test, y_pred)
    rec = recall(y_test, y_pred)
    return 2 * (prec * rec) / (prec + rec) if prec + rec != 0 else 0

def confusion_matrix(y_test, y_pred):
    tp = np.sum((y_test == 1) & (y_pred == 1))
    fp = np.sum((y_test == 0) & (y_pred == 1))
    tn = np.sum((y_test == 0) & (y_pred == 0))
    fn = np.sum((y_test == 1) & (y_pred == 0))
    return np.array([[tn, fp], [fn, tp]])

def classification_report(y_test, y_pred):
    prec = precision(y_test, y_pred)
    rec = recall(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    acc = accuracy(y_test, y_pred)

    report = {
        'accuracy': acc,
        'precision': prec,
        'recall': rec,
        'f1-score': f1
    }
    return report

print(f"Accuracy: {accuracy(y_test, y_pred) * 100:.2f}%")
print(f"Precision: {precision(y_test, y_pred) * 100:.2f}%")
print(f"Recall: {recall(y_test, y_pred) * 100:.2f}%")
print(f"F1-Score: {f1_score(y_test, y_pred) * 100:.2f}%")
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("Classification Report:")
print(classification_report(y_test, y_pred))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.feature_selection import RFE
from scipy.stats import randint

df = pd.read_csv("diabetes2.csv")

print(df.head())

print(df.isnull().sum())

plt.figure(figsize=(8,6))
sns.countplot(x='Outcome', data=df, palette='coolwarm')
plt.title('Distribution of Diabetes Outcome')
plt.show()

df.hist(figsize=(12, 10), bins=20, color='steelblue', edgecolor='black')
plt.suptitle('Feature Distributions', fontsize=16)
plt.show()

plt.figure(figsize=(10,8))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm")
plt.title("Feature Correlation Heatmap")
plt.show()

X = df.drop(columns=['Outcome'])
y = df['Outcome']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

rf = RandomForestClassifier(n_estimators=100, random_state=42)
rfe = RFE(rf, n_features_to_select=5)
X_selected = rfe.fit_transform(X_scaled, y)
selected_features = df.columns[:-1][rfe.support_]
print("Selected Features:", selected_features)

X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42, stratify=y)

param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 20],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy', n_jobs=-1)
grid_search.fit(X_train, y_train)
print("Best Parameters:", grid_search.best_params_)
best_model = grid_search.best_estimator_

y_pred = best_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')
print(classification_report(y_test, y_pred))

plt.figure(figsize=(6,4))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

